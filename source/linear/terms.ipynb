{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terminology\n",
    "\n",
    "Before we start, we need to get a bit of terminology out of the way. Data Scientists come from a variety of backgrounds and techniques have been invented and reinvented under a variety of names in a number of fields. In order to get everyone on the same page, we're going to talk a little bit about terminology.\n",
    "\n",
    "Artificial Intelligence (AI) is concerned with building algorithms that enable computers to learn, understand, and solve problems. One subset of AI is Machine Learning. It might help to contrast ML with one of the older branches of AI, state space search. \n",
    "\n",
    "In state space search, a problem is specified terms of permitted states and actions that can be taken in those states. If you specify an end state as a goal, a state space search algorithm will find a series of actions that will get you from the current state to the goal.\n",
    "\n",
    "In contrast, a *supervised* machine learning algorithm takes data in the form of *examples* of inputs and outputs and returns a model of those examples. You can then supply different inputs to the model and get an appropriate output. Because of the relationship between inputs and an output, supervised machine learning is often thought of as function approximation or at least the modeling of pattern recognition with some sort of function (or, more broadly, mapping). \n",
    "\n",
    "Remember our old friend the coin with a probability of heads, $p$, and the observed outcomes 6 heads and 4 tails. We noted that it is impossible to know *for sure* what $p$ is from the data. In supervised machine learning, our problem is even more difficult. \n",
    "\n",
    "## Some Computational Learning Theory\n",
    "\n",
    "First, we have some notion of an output $y$ from a system. We may or may not be measuring that value correctly. Second, we think we know the inputs to the system $X$ but we must remember the known knowns, known unknowns, and unknown unknowns that factor into any data collection endeavor. So, at best, $X$, the variables we have, are a large subset of $\\mathbf{X}$, the true inputs, and are properly measured. It could be instead that $X$ and $\\mathbf{X}$ have only a small intersection.\n",
    "\n",
    "Third, there is, we hope, some actual relationship between $y$ and $X$ but we don't know the actual functional form, $\\mathbf{f}(X)$ anymore than we know $p$. Our approximation is $f(X)$.\n",
    "\n",
    "Fourth, $f(X)$ must be estimated and even for the same $f(X)$ there are different ways of estimating it, $g(X, y)$.\n",
    "\n",
    "So we use an algorithm to fit a model:\n",
    "\n",
    "$$f = g(X, y)$$\n",
    "\n",
    "where $g$ is the machine learning algorithm (we'll assume we're talking about \"supervised\" for now), $(y, X)$ are a tuple of output and input vectors, and $f$ is the model. The model can then be used:\n",
    "\n",
    "$$\\hat{y} = f(X)$$\n",
    "\n",
    "on new inputs $X$ to estimate values of $y$, which are called (by convention), $\\hat{y}$.\n",
    "\n",
    "It's interesting to note that one of the machine learning libraries for Python (and that we will be using), `scikit-learn`, has an API that mirrors these constructs exactly:\n",
    "\n",
    "```\n",
    "algorithm = LinearRegression()\n",
    "model = algorithm.fit(X, y) # g(X, y)\n",
    "y_hat = model.predict(X)    # f(X)\n",
    "```\n",
    "\n",
    "The constructor creates an instance of the algorithm that holds *metaparameters*. A `fit` method is called on the instance of the algorithm with training data, $X$ and $y$. This is basically $g(X, y)$. A `predict` method is then called on the model instance to predict new values from new $X$.\n",
    "\n",
    "We'll see this a lot more over the next few chapters.\n",
    "\n",
    "* If we think of the mean as supervised machine learning, what are $g(X, y)$ and $f(X)$?\n",
    "\n",
    "## More About X and y\n",
    "\n",
    "$X$ is a matrix of variables. Each column is called a *feature* (attribute, factor, variable, inputs) and $y$ is a vector of output values (target, response). Each column of $X$, $X_i$, can be a different data type (unlike a mathematical matrix) although the user has to be careful. Sometimes an algorithm $g$ will accept types that don't actually make sense for $f$.\n",
    "\n",
    "If $y$ is a numerical variable, this is called *regression* regardless of the actual $g$ used. If $y$ is a categorical variable, this is called *classification*. It is important to distinguish these uses because we can use can use *linear regression* to solve *regression* problems and we can use *logistic regression* to solve *classification* problems.\n",
    "\n",
    "In concrete terms, if you want to estimate things like price, age, IQ, or leaf volume, this is a regression problem. If you want to estimate a purchase outcome, religion, animal, or creditworthiness outcome, then this is a classification problem. This is important because not all algorithms, metrics, evaluation techniques are appropriate for both regression and classification.\n",
    "\n",
    "## Why Linear and Logistic Regression\n",
    "\n",
    "So why not dive directly into boosted random forests? Linear and logistic regression regularly top the \"must know\" lists of algorithms for data scientists...and for good reason.\n",
    "\n",
    "First, we can go very deeply into these models and understand how they work, their advantages, and disadvantages.\n",
    "\n",
    "Second, one of the key findings in data science is that with \"big\" data, simple models can perform extremely well and more time should generally be placed on refining the features (inputs, or in regression-speak, the *regressors*) to the models. Facebook does this for many of its machine learning applications.\n",
    "\n",
    "Third, simple models are often sufficient to get a project off the ground, to go from 0% to 60% instead of 92% to 93%. A fielded, simple data product with 3% lift is better than a complicated data product with 20% lift that never gets fielded, needs to be constantly re-tuned or nobody understands.\n",
    "\n",
    "Finally, and specifically with regard to all types of regression, they are useful when we are trying to explore relationships in our process rather than simply prediction. \n",
    "\n",
    "For example, if we use a neural network to model our system, we may get a very good model of the inputs to the outputs. However, we will not be able to understand *how* the inputs relate to the outputs. With a linear regression model, we may get a poorer model (or have to futz with it more) but we will be able to understand the relationship between inputs and outputs. Ultimately it depends on what we're trying to do with the model (and hence the George Box quote from before). This is a general tension between statistics-based methods and machine learning-based methods.\n",
    "\n",
    "Nevertheless, we will address more complicated approaches in later chapters (machine learning) because *big* is really relative to the problem space and you may not be able to find or create better features than what you have. In any case, you should always start with the simplest thing first.\n",
    "\n",
    "Regression as a technique comes out of the field of statistics although people have been working with regression for over 130 years. Sir Francis Galton presented regression for the first time in a lecture in [1877](http://www.amstat.org/publications/jse/v9n3/stanton.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (en685648)",
   "language": "python",
   "name": "en685648"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
